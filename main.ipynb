{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32ojjLt0TfSY"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **0) Приветствие!**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aytIxpTIkv_U"
      },
      "source": [
        "\n",
        "\n",
        "Здравстуйте, мы команда: \n",
        "\n",
        "**ТриП**\n",
        "\n",
        "\n",
        "1.   Просто\n",
        "2.   Понятно\n",
        "3.   По факту\n",
        "\n",
        "\n",
        "```\n",
        "# это был наш слоган по которому мы постараемся подвигаться \n",
        "# мы так же решили оставлять коментарии в отдельном блоке как сейчас\n",
        "```\n",
        "\n",
        "\n",
        "> По составу все просто\n",
        "\n",
        "\n",
        "*   **Я** -  Говорящие окно с текстом \n",
        "*   **Зырянов Дмитрий** - человек который придумал сам код и собрал комнду \n",
        "*   **Коломников Максим** - человек который придумал основной дизайн всего\n",
        "*   **Трепаков Денис** - человек восоздавший приложение для ползователя\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Я готов представить вам решение задачи по треку: \n",
        "\n",
        "**\"ИИ в образовании\"**\n",
        "\n",
        "\n",
        "```\n",
        "# Данное решение было собранно из многих кусков статьей из интернета\n",
        "```\n",
        "\n",
        "\n",
        "Ну так что приступим... \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFVLTsFsbnW4"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **1) Импорт библиотек**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arY-E2_0DmjB",
        "outputId": "35b4510f-3565-4ca0-c884-1ce5504d38cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-10-16 16:32:45--  https://storage.yandexcloud.net/natasha-navec/packs/navec_hudlit_v1_12B_500K_300d_100q.tar\n",
            "Resolving storage.yandexcloud.net (storage.yandexcloud.net)... 213.180.193.243, 2a02:6b8::1d9\n",
            "Connecting to storage.yandexcloud.net (storage.yandexcloud.net)|213.180.193.243|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53012480 (51M) [application/x-tar]\n",
            "Saving to: ‘navec_hudlit_v1_12B_500K_300d_100q.tar.5’\n",
            "\n",
            "navec_hudlit_v1_12B 100%[===================>]  50.56M  15.8MB/s    in 4.3s    \n",
            "\n",
            "2021-10-16 16:32:50 (11.8 MB/s) - ‘navec_hudlit_v1_12B_500K_300d_100q.tar.5’ saved [53012480/53012480]\n",
            "\n",
            "Requirement already satisfied: navec in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from navec) (1.19.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.6.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.62.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.0.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2021.10.8)\n",
            "Requirement already satisfied: rake-nltk in /usr/local/lib/python3.7/dist-packages (1.0.6)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /usr/local/lib/python3.7/dist-packages (from rake-nltk) (3.6.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (4.62.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (2021.10.8)\n",
            "Requirement already satisfied: pymorphy2[fast] in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (2.4.417127.4579844)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (0.7.2)\n",
            "Requirement already satisfied: DAWG>=0.8 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (0.8.0)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru in /usr/local/lib/python3.7/dist-packages (2.4.417127.4579844)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "! wget https://storage.yandexcloud.net/natasha-navec/packs/navec_hudlit_v1_12B_500K_300d_100q.tar\n",
        "! pip install navec\n",
        "! pip install nltk\n",
        "! pip install rake-nltk\n",
        "! pip install pymorphy2[fast]\n",
        "! pip install -U pymorphy2-dicts-ru\n",
        "\n",
        "\n",
        "\n",
        "#1\n",
        "from navec import Navec\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"stopwords\")\n",
        "from tqdm import tqdm\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from scipy.special import softmax\n",
        "\n",
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "morph = pymorphy2.MorphAnalyzer(lang='ru')\n",
        "\n",
        "\n",
        "\n",
        "#2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib \n",
        "import random\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeOX9KMLb4OG"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **2) Импорт файлов**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "FJbNOeuX9nJH",
        "outputId": "af98d451-fbf7-4bbd-afa9-2830a1d9a63b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>catalog</th>\n",
              "      <th>categotis</th>\n",
              "      <th>anim</th>\n",
              "      <th>lit</th>\n",
              "      <th>sport</th>\n",
              "      <th>mus</th>\n",
              "      <th>anim2</th>\n",
              "      <th>mus2</th>\n",
              "      <th>sport2</th>\n",
              "      <th>lit2</th>\n",
              "      <th>a_cng_c</th>\n",
              "      <th>a_cng_gl</th>\n",
              "      <th>a_cng_pril</th>\n",
              "      <th>s_cng_c</th>\n",
              "      <th>s_cng_gl</th>\n",
              "      <th>s_cng_pril</th>\n",
              "      <th>m_cng_c</th>\n",
              "      <th>m_cng_gl</th>\n",
              "      <th>m_cng_pril</th>\n",
              "      <th>l_cng_c</th>\n",
              "      <th>l_cng_gl</th>\n",
              "      <th>l_cng_pril</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>славка</td>\n",
              "      <td>животные</td>\n",
              "      <td>славка</td>\n",
              "      <td>романист</td>\n",
              "      <td>элемент</td>\n",
              "      <td>медиатр</td>\n",
              "      <td>Приапулиды</td>\n",
              "      <td>Ля</td>\n",
              "      <td>Open Encyclopedia Project</td>\n",
              "      <td>Эпос</td>\n",
              "      <td>заяц</td>\n",
              "      <td>прыгает</td>\n",
              "      <td>пушистый</td>\n",
              "      <td>тренер</td>\n",
              "      <td>учит</td>\n",
              "      <td>строгий</td>\n",
              "      <td>Бах</td>\n",
              "      <td>сочиняет</td>\n",
              "      <td>красивый</td>\n",
              "      <td>Пушкин</td>\n",
              "      <td>пишет</td>\n",
              "      <td>понятный</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>абелизавр</td>\n",
              "      <td>животные</td>\n",
              "      <td>абелизавр</td>\n",
              "      <td>нон</td>\n",
              "      <td>австралийский</td>\n",
              "      <td>шкатулка</td>\n",
              "      <td>JSTOR</td>\n",
              "      <td>Рондо</td>\n",
              "      <td>Шиллер</td>\n",
              "      <td>Уравнение</td>\n",
              "      <td>обезьяна</td>\n",
              "      <td>лазеет</td>\n",
              "      <td>милая</td>\n",
              "      <td>спортсмен</td>\n",
              "      <td>занимается</td>\n",
              "      <td>чесный</td>\n",
              "      <td>нота</td>\n",
              "      <td>извлекает</td>\n",
              "      <td>красивый</td>\n",
              "      <td>Гоголь</td>\n",
              "      <td>сочинять</td>\n",
              "      <td>понятный</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>абелизаврид</td>\n",
              "      <td>животные</td>\n",
              "      <td>абелизаврид</td>\n",
              "      <td>массовый</td>\n",
              "      <td>автоспорт</td>\n",
              "      <td>гитара</td>\n",
              "      <td>Аристотель</td>\n",
              "      <td>Греческий язык</td>\n",
              "      <td>Фридрих</td>\n",
              "      <td>Энеида</td>\n",
              "      <td>тигр</td>\n",
              "      <td>смотрет</td>\n",
              "      <td>пушистый</td>\n",
              "      <td>футбол</td>\n",
              "      <td>играет</td>\n",
              "      <td>правельный</td>\n",
              "      <td>гитара</td>\n",
              "      <td>дергает</td>\n",
              "      <td>красивый</td>\n",
              "      <td>Достоевский</td>\n",
              "      <td>выдумывать</td>\n",
              "      <td>понятный</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>абидозавр</td>\n",
              "      <td>животные</td>\n",
              "      <td>абидозавр</td>\n",
              "      <td>корпус</td>\n",
              "      <td>рок</td>\n",
              "      <td>шум</td>\n",
              "      <td>Гаптофитовые водоросли</td>\n",
              "      <td>Ассирийцы</td>\n",
              "      <td>Прыжки с шестом</td>\n",
              "      <td>Мемуары</td>\n",
              "      <td>кошка</td>\n",
              "      <td>видит</td>\n",
              "      <td>ловкая</td>\n",
              "      <td>тенис</td>\n",
              "      <td>кидает</td>\n",
              "      <td>спортивный</td>\n",
              "      <td>укулеле</td>\n",
              "      <td>играет</td>\n",
              "      <td>красивый</td>\n",
              "      <td>Толстой</td>\n",
              "      <td>думать</td>\n",
              "      <td>понятный</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>абиссобротула</td>\n",
              "      <td>животные</td>\n",
              "      <td>абиссобротула</td>\n",
              "      <td>текстов</td>\n",
              "      <td>биатлонистка</td>\n",
              "      <td>арфа</td>\n",
              "      <td>Вестхайде</td>\n",
              "      <td>Ниппур</td>\n",
              "      <td>Старофранцузский язык</td>\n",
              "      <td>Парщиков</td>\n",
              "      <td>медведь</td>\n",
              "      <td>кричит</td>\n",
              "      <td>быстрая</td>\n",
              "      <td>плавец</td>\n",
              "      <td>плавает</td>\n",
              "      <td>ленивый</td>\n",
              "      <td>фортепиана</td>\n",
              "      <td>двигает</td>\n",
              "      <td>красивый</td>\n",
              "      <td>Чехов</td>\n",
              "      <td>открывать</td>\n",
              "      <td>понятный</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6169</th>\n",
              "      <td>британский язык</td>\n",
              "      <td>музыка</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Кости</td>\n",
              "      <td>Французский язык</td>\n",
              "      <td>Национальная библиотека Франции</td>\n",
              "      <td>Шерер</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6170</th>\n",
              "      <td>карликовый зайчик</td>\n",
              "      <td>музыка</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Верблюдоводство</td>\n",
              "      <td>Нормативный контроль</td>\n",
              "      <td>Английский язык</td>\n",
              "      <td>Вильгельм</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6171</th>\n",
              "      <td>энциклопедический лексика брокгауза и ефрона</td>\n",
              "      <td>музыка</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Лососеобразные</td>\n",
              "      <td>Программная музыка</td>\n",
              "      <td>Зайцев</td>\n",
              "      <td>Марр</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6172</th>\n",
              "      <td>список стереотипов</td>\n",
              "      <td>музыка</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Оленеводство</td>\n",
              "      <td>Риман</td>\n",
              "      <td>Борис Константинович</td>\n",
              "      <td>Николай Яковлевич</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6173</th>\n",
              "      <td>нац</td>\n",
              "      <td>музыка</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Корова</td>\n",
              "      <td>Хуго</td>\n",
              "      <td>Тунхойхэ</td>\n",
              "      <td>Пение</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6174 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           catalog  ... l_cng_pril\n",
              "0                                           славка  ...   понятный\n",
              "1                                        абелизавр  ...   понятный\n",
              "2                                      абелизаврид  ...   понятный\n",
              "3                                        абидозавр  ...   понятный\n",
              "4                                    абиссобротула  ...   понятный\n",
              "...                                            ...  ...        ...\n",
              "6169                               британский язык  ...        NaN\n",
              "6170                             карликовый зайчик  ...        NaN\n",
              "6171  энциклопедический лексика брокгауза и ефрона  ...        NaN\n",
              "6172                            список стереотипов  ...        NaN\n",
              "6173                                           нац  ...        NaN\n",
              "\n",
              "[6174 rows x 22 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "name_data = 'corr_gibrid_5.5.4_'\n",
        "df_habr = pd.read_csv(f'{name_data}.csv')\n",
        "russian_stopwords = stopwords.words(\"russian\")\n",
        "\n",
        "\n",
        "df_habr.head()\n",
        "df_habr_clean = df_habr.loc[df_habr['categotis'].isin(['животные', 'спорт', 'литература', 'музыка'])]\n",
        "\n",
        "df_habr_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "ZvuuotN0IvAE",
        "outputId": "030bb460-7f85-45af-a2eb-48cae611afa6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>task</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>\\nИспользуя данные круговой диаграммы, реши за...</td>\n",
              "      <td>спорт</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>\\nРеши задачу.\\nСредняя солёность добавок в ко...</td>\n",
              "      <td>животные</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>\"Вы с другом запланировали небольшие велогонки...</td>\n",
              "      <td>спорт</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>\"Прочитай текст в учебнике, посвящённый пропор...</td>\n",
              "      <td>литература</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1-й вопрос\\n\\nЗаполни пропуски (все слова даны...</td>\n",
              "      <td>спорт</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                               task    category\n",
              "0   1  \\nИспользуя данные круговой диаграммы, реши за...       спорт\n",
              "1   2  \\nРеши задачу.\\nСредняя солёность добавок в ко...    животные\n",
              "2   3  \"Вы с другом запланировали небольшие велогонки...       спорт\n",
              "3   4  \"Прочитай текст в учебнике, посвящённый пропор...  литература\n",
              "4   5  1-й вопрос\\n\\nЗаполни пропуски (все слова даны...       спорт"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "test = pd.read_csv('dataset_disclosed.csv')\n",
        "test.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdJ18d1g20bu",
        "outputId": "db56a635-1ebb-4f8c-8bcc-bb2db72bd856"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 57/57 [00:00<00:00, 256794.12it/s]\n"
          ]
        }
      ],
      "source": [
        "navec = Navec.load('navec_hudlit_v1_12B_500K_300d_100q.tar')\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    a = np.array(a)\n",
        "    b = np.array(b)\n",
        "\n",
        "    return np.dot(a, b) / np.linalg.norm(a) / np.linalg.norm(b)\n",
        "\n",
        "animalTexts = [x for x in df_habr['anim']][:1606]\n",
        "musicTexts = [x for x in df_habr[\"mus\"]][:1606]\n",
        "sportTexts = [x for x in df_habr[\"sport\"]][:1606]\n",
        "literatureTexts = [x for x in df_habr[\"lit\"]][:1606]\n",
        "\n",
        "allTexts = (animalTexts, musicTexts, sportTexts, literatureTexts)\n",
        "\n",
        "categories = (\"животные\", \"музыка\", \"спорт\", \"литература\")\n",
        "allTexts = [\n",
        "            [[token.strip() for token in nltk.word_tokenize(' '.join(text).lower())] for text in text_category] for text_category in allTexts\n",
        "]\n",
        "\n",
        "token_sets = {\n",
        "    'животные': set(sum(allTexts[0], [])),\n",
        "    'музыка': set(sum(allTexts[1], [])),\n",
        "    'спорт': set(sum(allTexts[2], [])),\n",
        "    'литература': set(sum(allTexts[3], [])),\n",
        "}\n",
        "\n",
        "non_exclusive_words = set()\n",
        "for word in tqdm(set.union(*token_sets.values())):\n",
        "    count = 0\n",
        "    for word_set in token_sets.values():\n",
        "        if word in word_set:\n",
        "            count += 1\n",
        "\n",
        "    if count > 1:\n",
        "        non_exclusive_words.add(word)\n",
        "\n",
        "exclusive_word_sets = {name: word_set - non_exclusive_words for name, word_set in token_sets.items()}\n",
        "stopWordsRu = set(stopwords.words(\"russian\"))\n",
        "punc = set(punctuation + '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~-—')\n",
        "\n",
        "def token_to_embed_id(word):\n",
        "    \n",
        "    if word in stopWordsRu or word in punc:\n",
        "        return None\n",
        "\n",
        "    \n",
        "    if word in navec.vocab:\n",
        "        return navec.vocab[word]\n",
        "\n",
        " \n",
        "    for category_name, exclusive_word_set in exclusive_word_sets.items():\n",
        "         if word in exclusive_word_set:\n",
        "             return navec.vocab[category_name]\n",
        "\n",
        "    return navec.vocab['<unk>']\n",
        "\n",
        "\n",
        "def text_to_ids(text: str):\n",
        "    tokens = []\n",
        "    embed_ids = []\n",
        "    for word in nltk.word_tokenize(text):\n",
        "        word = word.strip().lower()\n",
        "        embed_id = token_to_embed_id(word)\n",
        "\n",
        "        if embed_id is not None:\n",
        "            tokens.append(word)\n",
        "            embed_ids.append(embed_id)\n",
        "    return tokens, embed_ids\n",
        "classes = [\n",
        "           'животные',\n",
        "           'спорт',\n",
        "           'музыка',\n",
        "           'литература'\n",
        "]\n",
        "\n",
        "classes_emb = [\n",
        "               navec[class_name] for class_name in classes\n",
        "]\n",
        "\n",
        "def get_sentence_predictions(sentence: str):\n",
        "    tokens, embed_ids = text_to_ids(sentence)\n",
        "    \n",
        "    embeddings = np.array([navec.pq[embed_id] for embed_id in embed_ids])\n",
        "    mean_emb = embeddings.sum(axis=0)\n",
        "    \n",
        "    results =[\n",
        "        np.dot(class_emb, mean_emb) for class_emb in classes_emb\n",
        "    ]\n",
        "\n",
        "    results = softmax(results)\n",
        "\n",
        "    return results\n",
        "\n",
        "def get_word_significancy(sentence: str, class_: int):\n",
        "    tokens, embed_ids = text_to_ids(sentence)\n",
        "\n",
        "    embeddings = np.array([navec.pq[embed_id] for embed_id in embed_ids])\n",
        "\n",
        "    results = [\n",
        "        (cosine_similarity(token_emb, classes_emb[class_]), token) for token, token_emb in zip(tokens, embeddings)\n",
        "    ]\n",
        "    return sorted(results, reverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YuAbESocJv3"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **3) Показ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ko4S-0Od7Sp"
      },
      "source": [
        "Здесь толко малая часть из функция которые я использовал например:\n",
        "\n",
        "\n",
        "\n",
        "Код ниже это нглядная визуализация как я использовал Embedding слов\n",
        "```\n",
        "# еше ниже\n",
        "{(-0.04316089, 'каое-то'), (0.11974076, 'приложение'), (0.4995613, 'спорте')}\n",
        "```\n",
        "каждое слово имеет свой так называемый вес на ту или иную категорию\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqgIvN83WumE",
        "outputId": "40568759-2478-43ce-9fed-e49d65ab3889"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.0176993e-10 9.9682170e-01 7.0471418e-10 3.1781646e-03]\n",
            "{(-0.04316089, 'каое-то'), (0.11974076, 'приложение'), (0.4995613, 'спорте')}\n",
            "спорт\n"
          ]
        }
      ],
      "source": [
        "sen=text_to_ids(\"Тут каое-то приложение о спорте \")\n",
        "preds = get_sentence_predictions(' '.join(sen[0]))\n",
        "word_significancy = set(get_word_significancy(' '.join(sen[0]), np.argmax(preds)))\n",
        "print(preds)\n",
        "print(word_significancy)\n",
        "print(classes[np.argmax(preds)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0qMyVrme4ad"
      },
      "source": [
        "Код ниже это нглядная визуализация как я использовал библиотеку pymorphy2 а именно:\n",
        "\n",
        "1. Я получаю всю информацию о слове (роде,месте,времени и тд) \n",
        "2. Я изменяю уже новое слова по полученным данным \n",
        "3. и последнее это уже замена одного слова другим уже измененым(по роду,числу и тд)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgfA6es7IRCL",
        "outputId": "c950c758-dbec-4751-a1f7-ae1ede6daad4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nomn\n",
            "животным\n",
            "-*------------\n",
            "СУЩ,од,мр ед,им\n",
            "ИНФ,несов,перех\n",
            "не то\n",
            "``\n"
          ]
        }
      ],
      "source": [
        "p = morph.parse(\"птицевод\")[0].tag.case\n",
        "print(p)\n",
        "print(morph.parse(\"животное\")[0].inflect({'ablt'}).word)\n",
        "\n",
        "print('-*------------')\n",
        "old_word = \"человек\"\n",
        "info = str(morph.parse(old_word)[0].tag).split(',')\n",
        "print(morph.parse(old_word)[0].tag.cyr_repr)\n",
        "rec = info[0]\n",
        "info = info[1:]\n",
        "info= info + info[1].split()\n",
        "del info[1] \n",
        "\n",
        "\n",
        "nem_word = 'делать'\n",
        "print(morph.parse(nem_word)[0].tag.cyr_repr)\n",
        "\n",
        "if rec == morph.parse(word)[0].tag.POS:\n",
        "  for i in info:\n",
        "    try:\n",
        "      word = morph.parse(word)[0].inflect({i}).word\n",
        "    except:\n",
        "      pass\n",
        "else:\n",
        "  print('не то')\n",
        "print(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1VeiJwLcSAt"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **4) Основной замысел**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPcc93lEhXSa"
      },
      "source": [
        "Здесь я отмечу только несколько уловок \n",
        "\n",
        "1. Это то что я удаляю очень много не нужных слов и это приводит к тому, то что нахождение ключевых слов намного легче и точно дается имбеденгу\n",
        "2. Это то что если в приложении есть хотябы одно имя, то я его заменяю на слово которе более сильно относиться к категории, которую задал пользователь\n",
        "3. Это то что функция calss_class бирет в себя 3 параметра -  это: вопрос, категория(которую задал пользователь) и категория к каторой относится вопрос. \n",
        "\n",
        "*Ps*..  Это сделано потому что если категория(которую задал пользователь) == категория(задачи) то смысл менять задачу я не вижу. (Да можно и без этого но я лишний раз перестраховался)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uat0iodQAtzV",
        "outputId": "a74b3ef2-c118-4964-f300-27d27c594d34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Вопрос 1\n",
            "Пушкин любит кататься на велосипеде с подружками. Но ещё больше Пушкин хочет попасть в городскую команду по велокроссу. Поэтому она решила тренироваться всё лето, чтобы в сентябре пройти отбор и попасть в команду.\n",
            "Пушкин и её папа составили программу тренировок, по которой девочка должна с каждой тренировкой проезжать расстояние на 6% больше, чем в предыдущей тренировке.\n",
            "Какое расстояние проехала Пушкин на последней тренировке в июне, если во время первой тренировки она проехала 2 км, а всего за месяц провела 10 тренировок?\n",
            "При вычислениях округляй результаты до целого числа, проводи вычисления для точности в метрах.\n",
            "Введи ответ без пробелов и единиц измерения. Переведи результат в км и округли до сотых.\n",
            "На последней тренировке в июне Пушкин проехала на велосипеде … км.\n"
          ]
        }
      ],
      "source": [
        "def calss_class(qwes,class_trans,stop_class):\n",
        "\n",
        "  pun =  punctuation + '!\"#$%&()*+,-. /:;<=>?@[\\]^_`{|}~-—'\n",
        "\n",
        "  nonono_pun = qwes.translate(str.maketrans('', '', punctuation + '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~-—'))\n",
        "\n",
        "  all = [x.lower() for x in pd.read_csv('all_stop.csv')['stop'][:1345]]\n",
        "  names = [x.lower() for x in pd.read_csv('all_stop.csv')['names']]\n",
        "\n",
        "\n",
        "\n",
        "  edit_string_as_list = nonono_pun.lower().split()\n",
        "  final_list = [word for word in edit_string_as_list if word not in all]\n",
        "\n",
        "  final_list =[x for x in final_list if not (x.isdigit() or x[0] == '-' and x[1:].isdigit())]\n",
        "  final_string = ' '.join(final_list)\n",
        "\n",
        "\n",
        "  p2 = get_sentence_predictions(final_string)\n",
        "  word_significancy2 = set(get_word_significancy(final_string, np.argmax(p2)))\n",
        "  nme = ''\n",
        "\n",
        "  for x in final_list:\n",
        "    if x in names:\n",
        "      nme = nme + \" \" + x.title()\n",
        "  if nme == '':\n",
        "    isNameTxt = False\n",
        "  else:\n",
        "    isNameTxt = True\n",
        "  key2 = ''\n",
        "  if not isNameTxt:\n",
        "    \n",
        "    count = 0\n",
        "    #Так же вот ниже до -- я отлавливаю список ключевых слов\n",
        "    if len(final_list) > 5 and len(final_list) < 10 :\n",
        "      while count != 4:\n",
        "        try:\n",
        "          if len(max(word_significancy2)[1]) > 2:\n",
        "            key2 =key2 + max(word_significancy2)[1]+\" \"\n",
        "            word_significancy2.remove(max(word_significancy2)) \n",
        "            count = count+1\n",
        "          else:\n",
        "            word_significancy2.remove(max(word_significancy2)) \n",
        "        except:\n",
        "          break\n",
        "    elif len(final_list) == 1:\n",
        "      key2 =final_string\n",
        "    elif len(final_list) == 2:\n",
        "      while count != 1:\n",
        "          try:\n",
        "            if len(max(word_significancy2)[1]) > 2:\n",
        "              key2 =key2 + max(word_significancy2)[1]+\" \"\n",
        "              word_significancy2.remove(max(word_significancy2)) \n",
        "              count = count+1\n",
        "            else:\n",
        "              word_significancy2.remove(max(word_significancy2)) \n",
        "          except:\n",
        "            break\n",
        "    elif len(final_list) == 3:\n",
        "      while count != 1:\n",
        "          try:\n",
        "            if len(max(word_significancy2)[1]) > 2:\n",
        "              key2 =key2 + max(word_significancy2)[1]+\" \"\n",
        "              word_significancy2.remove(max(word_significancy2)) \n",
        "              count = count+1\n",
        "            else:\n",
        "              word_significancy2.remove(max(word_significancy2)) \n",
        "          except:\n",
        "            break\n",
        "    else:\n",
        "      while count != 4:\n",
        "          try:\n",
        "            if len(max(word_significancy2)[1]) > 2:\n",
        "              key2 =key2 + max(word_significancy2)[1]+\" \"\n",
        "              word_significancy2.remove(max(word_significancy2)) \n",
        "              count = count+1\n",
        "            else:\n",
        "              word_significancy2.remove(max(word_significancy2)) \n",
        "          except:\n",
        "            break\n",
        "  else:\n",
        "    key2=nme\n",
        "#------------------\n",
        "\n",
        "  def slowa_del(sy,pril,prilk,gl,inf,prics,prics_k,deep,new,nammes):\n",
        "    for i,el in enumerate(key2.split()): \n",
        "      old_word = el\n",
        "      try:\n",
        "        info = str(morph.parse(old_word)[0].tag).split(',')\n",
        "        rec = info[0]\n",
        "        info = info[1:]\n",
        "        info= info + info[1].split()\n",
        "        del info[1] \n",
        "      except:\n",
        "        pass\n",
        "      nem_word = ''\n",
        "      if not isNameTxt:\n",
        "        if rec == 'NOUN':\n",
        "          nem_word = sy[i]\n",
        "        elif rec == 'ADJF':\n",
        "          nem_word = pril[i]\n",
        "        elif rec == 'ADJS':\n",
        "          nem_word = prilk[i]\n",
        "        elif rec == 'VERB':\n",
        "          nem_word = gl[i]  \n",
        "        elif rec == 'INFN':\n",
        "          nem_word = inf[i]\n",
        "        elif rec == 'PRTF':\n",
        "          nem_word = prics[i]\n",
        "        elif rec == 'GRND':\n",
        "          nem_word = deep[i]\n",
        "        elif rec == 'PRTS':\n",
        "          nem_word = prics_k[i]\n",
        "        \n",
        "        else:\n",
        "          nem_word = el\n",
        "      else:\n",
        "          nem_word = nammes[i]\n",
        "\n",
        "\n",
        "      word = nem_word\n",
        "      try:\n",
        "          if rec == morph.parse(word)[0].tag.POS:\n",
        "            for i in info:\n",
        "              try:\n",
        "                word = morph.parse(word)[0].inflect({i}).word\n",
        "              except:\n",
        "                pass\n",
        "              if class_trans == 'животные':\n",
        "                new = new.replace(el,word)\n",
        "              else:\n",
        "                new = new.replace(el.title(),word.title())\n",
        "            \n",
        "\n",
        "          else:\n",
        "            new = new.replace(el.title(),word.title())\n",
        "            pass\n",
        "      except:\n",
        "        \n",
        "          for i in info:\n",
        "            try:\n",
        "              word = morph.parse(word)[0].inflect({i}).word\n",
        "            except:\n",
        "              pass\n",
        "        \n",
        "    \n",
        "    return new\n",
        "\n",
        "  new = qwes\n",
        "\n",
        "  if stop_class == class_trans:\n",
        "      new = qwes\n",
        "  elif class_trans == 'животные':\n",
        "      key_sy_a = [random.choice('зверь хищник обезьяна леопард коати кошка детёныш волк гиена тигр павиан сервал собака зверёк кролик вольера зверюга живность грызун сородич поссум агути вольер птица койот гепард барс пантера носуха олень смилодон ягуар бабуин медведь зверинец лемур тварь лисица тигрица оцелот зверьё животина антилопа кабанёнок виверра цератозавр пума крокодил кинкажу кугуар'.split()) for _ in key2.split()]#Сущ\n",
        "      key_pr_a = [random.choice('животный двуногий четвероногий дикий травоядный бесхвостый бесшёрстный первобытный человечий сумчатый енотовидный шерстистый саблезубый человеческий пугливый пещерный парнокопытный человекообразный копытный звериный кенгуровый длиннохвостый хищный длинношёрстый кошачий плотоядный водоплавающий чепрачный короткохвостый короткошёрстый остромордый длиннорогий длинношеий свирепый длинношёрстный белолобый свиноподобный полудикий яйцекладущий двухголовый зоологический кровожадный пятнистый псовый короткошёрстный стайный обезьяний собакообразный кроликовый всеядный'.split()) for _ in key2.split()]#прил полное\n",
        "      key_pr_k_a = [random.choice(['мягок','пушист','гладок']) for _ in key2.split()]#прил краткое\n",
        "      key_gl_a = [random.choice([x for x in df_habr_clean['a_cng_gl'][:11]]) for _ in key2.split()]#глагол\n",
        "      key_inf_a = [random.choice(['прыгать','плавать','етсь','смотреть','лететь']) for _ in key2.split()]#как глагол но окончание -ть\n",
        "      key_prics_a = [random.choice(['приручённый одомашненный приручаемый охотящийся учуявший одичавший обитающий похрюкивающий почуявший околевающий спаривающийся выдрессированный мяукавший вспугнувший загрызенный повизгивавший рычащий взбесившийся ласкающийся обезумевший питающийся лазающий хрюкающий дрессируемый обитавший охотившийся водящийся приручивший обнюхивающий бесившийся выкормленный ощенившийся завидевший обнюхивавший бродивший издохший зарычавший заскуливший рычавший лаявший водившийся издыхающий подстреленный убиваемый обезумивший лакомившийся унюхавший кастрированный вспугнутый мяукающий'.split()]) for _ in key2.split()]#причастие \n",
        "      key_prics_k_a = [random.choice(['проплыто','проедено','просмотрено','осмотрено']) for _ in key2.split()]#кратное причастие \n",
        "      key_deep_a = [random.choice(['присесть','проев','прилечь']) for _ in key2.split()]# деепр\n",
        "\n",
        "      key_namess_a = key_sy_a\n",
        "\n",
        "      new = slowa_del(key_sy_a,key_pr_a,key_pr_k_a,key_gl_a,key_inf_a,key_prics_a,key_prics_k_a,key_deep_a,new,key_namess_a)\n",
        "\n",
        "  elif class_trans == 'литература':\n",
        "      key_sy_l = [random.choice('литература беллетристика проза классики автор антология писатель сочинение сборник произведение эссе читатель стихи повесть нон-фикшн хрестоматия публицистика поэма литературовед очерк опус стихотворение однотомник романист книга двухтомник писательство заглавие роман новелла классика сочинительство классик переиздание жизнеописание литератор библиография мемуаристика послесловие поэт поэзия рецензия словесность отрывок жанр прозаик беллетрист предисловие трёхтомник эпиграф'.split()) for _ in key2.split()]\n",
        "      key_pr_l= [random.choice('литературный беллетристический литературоведческий автобиографический многотомный стихотворный двухтомный мемуарный трёхтомный читательский художественный очерковый поэтический публицистический научно-фантастический компилятивный автобиографичный популяризаторский текстологический юмористический прозаический сатирический писательский подстрочный нравоописательный первопечатный жанровый пушкинский переводной романный эпистолярный реалистический приключенческий злободневный памфлетный биографический фельетонный островской повествовательный символистский драматургический балладный новеллистический эсперантский рукописный антологический энциклопедический цитатный эпический силлабический'.split()) for _ in key2.split()]\n",
        "      key_pr_k_l= [random.choice('литературный беллетристический литературоведческий автобиографический многотомный стихотворный двухтомный мемуарный трёхтомный читательский художественный очерковый поэтический публицистический научно-фантастический компилятивный автобиографичный популяризаторский текстологический юмористический прозаический сатирический писательский подстрочный нравоописательный первопечатный жанровый пушкинский переводной романный эпистолярный реалистический приключенческий злободневный памфлетный биографический фельетонный островской повествовательный символистский драматургический балладный новеллистический эсперантский рукописный антологический энциклопедический цитатный эпический силлабический'.split()) for _ in key2.split()]\n",
        "      key_gl_l= [random.choice([x for x in df_habr_clean['l_cng_gl'][:11]]) for _ in key2.split()]\n",
        "      key_inf_l= [random.choice('переиздавать писаться писать читать рецензировать переиздать отрецензировать зачитываться печататься цитировать экранизировать озаглавить напечататься редактировать написать сочинять исписаться перечитывать прочитывать опубликовать переосмыслять публиковать пописывать зарифмовать процитировать почитывать рифмовать читывать исписываться повествовать перепечатывать посвящаться почерпнуть опоэтизировать предпослать штудировать кропать вдохновляться отредактировать дописываться дочитывать перелагать прочесть дописывать заучиваться затверживать поэтизировать переписываться прочитать думаться'.split()) for _ in key2.split()]\n",
        "      key_prics_l= [random.choice(['переизданный читающий печатавшийся опубликованный печатаемый цитируемый зарифмованный написавший печатающийся прочитанный писавшийся напечатавший прочитавший предпосланный написанный изданный экранизированный писавший аннотированный посвящённый процитированный публикуемый комментированный литографированный сочинявший цитированный публиковавший рецензируемый цензурованный сочиняющий читанный прочтённый вычитанный почерпнутый озаглавленный прокомментированный дочитанный вдохновивший перепечатанный сочиняемый изображаемый опоэтизированный перебелённый цитирующий обессмертивший печатанный излагающий опубликовавший пародируемый поэтизированный'.split()]) for _ in key2.split()]\n",
        "      key_prics_p_l= [random.choice(['прочитавшх']) for _ in key2.split()]\n",
        "      key_deep_l= [random.choice(['дописывая']) for _ in key2.split()]\n",
        "\n",
        "      key_namess_l= [random.choice(['Толстой','Гоголь','Фет','Пушкин','Чехов','Ершов','Тютчев'])for _ in key2.split()]\n",
        "\n",
        "      new = slowa_del(key_sy_l,key_pr_l,key_pr_k_l,key_gl_l,key_inf_l,key_prics_l,key_prics_p_l,key_deep_l,new,key_namess_l)\n",
        "\n",
        "  elif class_trans == 'музыка':\n",
        "      key_sy_m = [random.choice('музыка мелодия блюз музыкант скрипка аккорд саксофон гитара джаз оркестр фортепьяно виолончель аккомпанемент флейта маримба песня электрогитара аккордеон бас-гитара фортепиано аранжировка нота джаз-оркестр цитра квартет клавесин гитарист соната мандолина рок-н-ролл симфония пение арфа оркестрик пианино бэк-вокал рок-ансамбль диксиленд солист кларнет кантри скрипач валторна корнет-а-пистон рояль вокал певец тромбон звучание полутакт'.split()) for _ in key2.split()]\n",
        "      key_pr_m = [random.choice('музыкальный джазовый фортепьянный лютневый саксофонный симфонический трёхструнный скрипичный клавесинный органный струнный бравурный многострунный клавишный гитарный минорный сладкозвучный теноровый плясовой сольный танцевальный какофонический оркестровый виолончельный мелодический многоголосный вокальный хоровой семиструнный басовый шестиструнный камерный немузыкальный концертный полифонический контральтовый аккордовый сонатный напевный диатонический смычковый песенный лиричный колоратурный эолов филармонический полнозвучный разухабистый мажорный оперный'.split()) for _ in key2.split()]\n",
        "      key_pr_k_m = [random.choice(['музыкален']) for _ in key2.split()]\n",
        "      key_gl_m = [random.choice([x for x in df_habr_clean['m_cng_gl'][:11]]) for _ in key2.split()]\n",
        "      key_inf_m = [random.choice('аккомпанировать наигрывать подпевать солировать петь музицировать фальшивить аранжировать наяривать спеть допевать разучить наиграть дирижировать запеть зазвучать допеть заиграть распеваться сфальшивить пиликать разучивать выпевать танцевать оркестровать концертировать потренькать напеть тренькать транспонировать певать запевать бисировать бренчать подпеть трелить бацать импровизировать дотанцевать отзвучать высвистывать подыгрывать интонировать перепеть напевать подтанцовывать станцевать вторить распевать насвистеть'.split()) for _ in key2.split()]\n",
        "      key_prics_m = [random.choice(['прочитавший','прочитанная']) for _ in key2.split()]\n",
        "      key_prics_p_m = [random.choice(['прочитана']) for _ in key2.split()]\n",
        "      key_deep_m = [random.choice(['прочитав','рассказывая']) for _ in key2.split()]\n",
        "\n",
        "\n",
        "      key_namess_m = [random.choice(['Бетховен','Бах','Моцарт','Чайковский','Рахманинов','Шуберт']) for _ in key2.split()]\n",
        "\n",
        "\n",
        "      new = slowa_del(key_sy_m,key_pr_m,key_pr_k_m,key_gl_m,key_inf_m,key_prics_m,key_prics_p_m,key_deep_m,new,key_namess_m)\n",
        "\n",
        "\n",
        "  elif class_trans == 'спорт':\n",
        "    key_sy_s = [random.choice('спорт атлетика спортсмен баскетбол хоккей футбол велоспорт гандбол чемпион тренер теннис футболист пятиборье соревнование велогонки волейбол биатлон чемпионат триатлон фристайл регби хоккеист чемпионка теннисист мини-футбол десятиборье бейсбол легкоатлет троеборье спартакиада мотокросс пауэрлифтинг болельщик крикет картинг сноубординг ватерполист еврокубок волейболист футболистка спортшкола кикбоксинг софтбол матч дельтапланеризм бадминтон атлетизм спортсменка культуризм тренировка'.split()) for _ in key2.split()]\n",
        "    key_pr_s = [random.choice('олимпийский конькобежный легкоатлетический тренерский спортивный хоккейный соревновательный футбольный предсезонный полуфинальный гиревой кубковый чемпионский волейбольный неспортивный баскетбольный беговой тяжелоатлетический физкультурный стайерский полутяжёлый техничный общефизический конноспортивный турниковый отборочный клубный спартаковский игровой гимнастический боксёрский авиамодельный стоклеточный любительский теннисный планёрный тренировочный горнолыжный межзональный спринтерский комбинационный турнирный бейсбольный лыжный зрелищный фигурный марафонский призовой азартный стадионный'.split()) for _ in key2.split()]\n",
        "    key_pr_k_s = [random.choice(['болюч','быстр','гибок','ловок','вынослив']) for _ in key2.split()]\n",
        "    key_gl_s = [random.choice([x for x in df_habr_clean['s_cng_gl'][:11]]) for _ in key2.split()]\n",
        "    key_inf_s = [random.choice(['учить','играть','ходить','бегать','плавть','бить']) for _ in key2.split()]\n",
        "    key_prics_s = [random.choice('дисквалифицированный тренирующийся разминающийся соревнующийся выигрывавший проигрывающий развивающий засчитанный гоняющий тренирующий гонявший выигрывающий тренировавшийся игравший выигравший проигравший уделяющий состязающийся состязавшийся выигранный увлекавшийся побивший подкачанный оттачивающий тренируемый добившийся накаченный присуждаемый пасующий переигранный накачанный упражняющийся концертирующий нокаутирующий отгадавший блефующий проигрывавший соревновавшийся загоравший побеждавший катающийся обучаемый победивший доигранный подбадривавший отбивающий отдышавшийся догоняющий разыгрывающий угадавший'.split()) for _ in key2.split()]\n",
        "    key_prics_k_s = [random.choice('разомнулся потренировался выигрывана проиграна'.split()) for _ in key2.split()]\n",
        "    key_deep_s = [random.choice('проиграть выиграть дисквалифицировать'.split()) for _ in key2.split()]\n",
        "\n",
        "\n",
        "    key_namess_s = [random.choice(['Роналдо','Лионель Месси','Дзюба','Неймар','Хабиб']) for _ in key2.split()]\n",
        "\n",
        "\n",
        "    new = slowa_del(key_sy_s,key_pr_s,key_pr_k_s,key_gl_s,key_inf_s,key_prics_s,key_prics_k_s,key_deep_s,new,key_namess_s)\n",
        "\n",
        "\n",
        "\n",
        "  new = new[0].upper() + new[1:]\n",
        "\n",
        "  return new\n",
        "\n",
        "\n",
        "print(calss_class(test.task[99],'литература',test.category[99]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u97uwwrqccng"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **5) Export**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "0pqnGmlzMcm-"
      },
      "outputs": [],
      "source": [
        "As = []\n",
        "Ss =[]\n",
        "Ls = []\n",
        "Ms = []\n",
        "\n",
        "for i in range(len(test.task)):\n",
        "  As.append(calss_class(test.task[i],'животные',test.category[i]))\n",
        "  Ss.append(calss_class(test.task[i],'спорт',test.category[i]))\n",
        "  Ls.append(calss_class(test.task[i],'литература',test.category[i]))\n",
        "  Ms.append(calss_class(test.task[i],'музыка',test.category[i]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "KpeIFbV-80Pj"
      },
      "outputs": [],
      "source": [
        "sample = pd.read_csv('test_finals.csv')\n",
        "sample['sport'] = Ss\n",
        "sample['music'] = Ms\n",
        "sample['literature'] = Ls\n",
        "sample['animals'] = As\n",
        "sample.to_csv('Trip_Bot_cng.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6yA9S7RcjWf"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "#  \n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "32ojjLt0TfSY",
        "GFVLTsFsbnW4",
        "eeOX9KMLb4OG",
        "3YuAbESocJv3",
        "S1VeiJwLcSAt",
        "u97uwwrqccng"
      ],
      "name": "corr_pril.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
